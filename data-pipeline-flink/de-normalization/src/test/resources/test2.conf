include "base-test.conf"

kafka {
  input.telemetry.topic = "flink.telemetry.unique"
  input.summary.topic = "flink.telemetry.derived"
  telemetry.denorm.output.topic = "flink.telemetry.denorm"
  summary.denorm.output.topic = "flink.druid.events.summary"
  summary.unique.events.topic = "flink.telemetry.derived.unique"
  output.failed.topic = "flink.telemetry.failed"
  output.duplicate.topic = "flink.telemetry.duplicate"
  groupId = "flink-telemetry-denorm-group"
}

task {
  telemetry.downstream.operators.parallelism = 1
  summary.downstream.operators.parallelism = 1
}

redis {
  host = 127.0.0.1
  port = 6340
  database {
    duplicationstore.id = 9
    key.expiry.seconds = 3600
  }
}

redis-meta {
  host = 127.0.0.1
  port = 6340
  port1 = 6340
  port2 = 6340
  database {
    devicestore.id = 2
    userstore.id = 12
    contentstore.id = 5
    dialcodestore.id = 6
  }
}

//version
user_denorm_version = v1

telemetry.ignore.period.months = 6
summary.filter.events = ["ME_WORKFLOW_SUMMARY","ME_RANDOM_SUMMARY"]
user.signin.type.default = "Default"
user.login.type.default = "Google"